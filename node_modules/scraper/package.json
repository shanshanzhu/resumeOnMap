{
  "name": "scraper",
  "description": "Easier web scraping using jQuery.",
  "version": "0.0.9",
  "author": {
    "name": "Mathias Pettersson",
    "email": "mape@mape.me"
  },
  "engines": [
    "node"
  ],
  "directories": {
    "lib": "./lib"
  },
  "main": "./lib/scraper",
  "repository": {
    "type": "git",
    "url": "https://github.com/mape/node-scraper.git"
  },
  "dependencies": {
    "request": ">=0.10.0",
    "jsdom": ">=0.1.20"
  },
  "readme": "# node-scraper\n\nA little module that makes scraping websites a little easier. Uses node.js and jQuery.\n\n## Installation\n\nVia [npm](http://github.com/isaacs/npm):\n\n    $ npm install scraper\n\n## Examples\n\n### Simple\nFirst argument is an url as a string, second is a callback which exposes a jQuery object with your scraped site as \"body\" and third is an object from the request containing info about the url.\n\n    var scraper = require('scraper');\n    scraper('http://search.twitter.com/search?q=javascript', function(err, jQuery) {\n        if (err) {throw err}\n\n        jQuery('.msg').each(function() {\n            console.log(jQuery(this).text().trim()+'\\n');\n        });\n    });\n### \"Advanced\"\nFirst argument is an object containing settings for the \"request\" instance used internally, second is a callback which exposes a jQuery object with your scraped site as \"body\" and third is an object from the request containing info about the url.\n\n    var scraper = require('scraper');\n    scraper(\n\t    {\n           'uri': 'http://search.twitter.com/search?q=nodejs'\n               , 'headers': {\n                   'User-Agent': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0)'\n               }\n        }\n        , function(err, $) {\n            if (err) {throw err}\n\n            $('.msg').each(function() {\n                console.log($(this).text().trim()+'\\n');\n            });\n        }\n    );\n### Parallel\nFirst argument is an array containing either strings or objects, second is a callback which exposes a jQuery object with your scraped site as \"body\" and third is an object from the request containing info about the url.\n\n**You can also add rate limiting to the fetcher by adding an options object as the third argument containing 'reqPerSec': float.**\n\n    var scraper = require('scraper');\n    scraper(\n\t    [\n            'http://search.twitter.com/search?q=javascript'\n            , 'http://search.twitter.com/search?q=css'\n            , {\n                'uri': 'http://search.twitter.com/search?q=nodejs'\n                , 'headers': {\n                    'User-Agent': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0)'\n                }\n            }\n            , 'http://search.twitter.com/search?q=html5'\n        ]\n        , function(err, $) {\n            if (err) {throw err;}\n\n            $('.msg').each(function() {\n                console.log($(this).text().trim()+'\\n');\n            });\n        }\n        , {\n            'reqPerSec': 0.2 // Wait 5sec between each external request\n        }\n    );\n\n\n\n## Arguments\n\n### First (required)\nContains the info about what page/pages will be scraped\n\n#### string\n    'http://www.nodejs.org'\n**or**\n\n#### request object\n    {\n       'uri': 'http://search.twitter.com/search?q=nodejs'\n           , 'headers': {\n               'User-Agent': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0)'\n           }\n    }\n**or**\n\n#### Array (if you want to do fetches on multiple URLs)\n    [\n        urlString\n        , urlString\n        , requestObject\n        , urlString\n    ]\n\n### Second (optional)\nThe callback that allows you do use the data retrieved from the fetch.\n\n    function(err, $) {\n        if (err) {throw err;}\n        \n        $('.msg').each(function() {\n            console.log($(this).text().trim()+'\\n');\n        }\n    }\n\n### Third (optional)\nThis argument is an object containing settings for the fetcher overall.\n\n* **reqPerSec**: float; (allows you to throttle your fetches so you don't hammer the server you are scraping)\n\n## Depends on\n* [tmpvar](https://github.com/tmpvar/)'s [jsdom](https://github.com/tmpvar/jsdom)\n* [mikeal](https://github.com/mikeal/)'s [request](https://github.com/mikeal/node-utils/tree/master/request)\n* [jquery](https://github.com/jquery/jquery)",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/mape/node-scraper/issues"
  },
  "homepage": "https://github.com/mape/node-scraper",
  "_id": "scraper@0.0.9",
  "dist": {
    "shasum": "c6d5d2a390a17cbd6790197eb1345aff1447dc0c"
  },
  "_from": "scraper@0.0.9",
  "_resolved": "https://registry.npmjs.org/scraper/-/scraper-0.0.9.tgz"
}
